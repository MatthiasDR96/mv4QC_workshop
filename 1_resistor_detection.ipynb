{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: resistor detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will determine the value of a resistor based on an image of that resistor. We will use classical image processing and Machine Learning to do the job. First, we will import all necessary modules that we need to get the job done. The next parts of the code are organized in: data analysis, data preprocessing, model training, and model validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os # Module to access Operating System\n",
    "import cv2 # Module for computer vision algorithms\n",
    "import numpy as np # Module for matrix operations and linear algebra\n",
    "import pandas as pd # Module for dataset handling\n",
    "from sklearn import svm # Module that implements a Support Vector Machine (Machine Learning algorithm)\n",
    "import matplotlib.pyplot as plt # Module for plotting\n",
    "from mpl_toolkits.mplot3d import Axes3D # Module for 3D plotting\n",
    "from sklearn.preprocessing import LabelEncoder # Module to encode string labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "if not os.path.exists('data/resistor_data'):\n",
    "    !wget -q --no-check-certificate -O dataset.zip \"https://kuleuven-my.sharepoint.com/:u:/g/personal/matthias_deryck_kuleuven_be/EQYSStulyl5CrPuiERAMpEsB0RMf4164Ng4zPzCtcDRcOA?e=K48wUZ&download=1\"\n",
    "    !wget -q --no-check-certificate -O utils.py \"https://kuleuven-my.sharepoint.com/:u:/g/personal/matthias_deryck_kuleuven_be/EXG1lB_iaLxBm1_7ppE0O20BgAzsKNZoV-fQ1Cro3MFFxA?e=TT3KY5&download=1\"\n",
    "    !unzip -q dataset.zip -d data\n",
    "    !rm dataset.zip\n",
    "\n",
    "# Import loaded functions\n",
    "from utils import * # Module that imports decode and extract_color_bands functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we will briefly analyze the data and show some data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file names of all images in the dataset (data/resistor_data/images)\n",
    "image_paths = os.listdir('./data/resistor_data/images/')\n",
    "\n",
    "# Print results\n",
    "print(f'There are {len(image_paths)} images in the dataset.')\n",
    "print(f'\\nThese are the file names of the first five images: {[path_name for path_name in image_paths[0:5]]}')\n",
    "print('\\nThe last three letters of the file names denote the code of the three color bands of the resistor in the image.')\n",
    "print('\\nThe color bands are encoded as follows: [k, z, r, o, y, g, b, v, x, w] -> [black, brown, red, orange, yellow, green, blue, violet, gray, white]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the first five images\n",
    "for path in image_paths[0:5]:\n",
    "\t\n",
    "\t# Read image\n",
    "\timage = cv2.imread('./data/resistor_data/images/' + path)\n",
    "\n",
    "\t# Extract the ground truth label from the file name\n",
    "\tlabel = path.split('_')[-1][0:3]\n",
    "\n",
    "    # Plot the label on the image in green\n",
    "\tcv2.putText(image, text=label + \" - \" + decode(label), org=(150, 250), fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=3, color=(0, 255, 0),thickness=3)\n",
    "\t\n",
    "\t# Show image\n",
    "\tprint(f'File name: {path}')\n",
    "\tplt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we will perform several image processing steps in order to extract the neccesary features from the image in order to be able to classify it in the right class. The features that we need to distinguish all images are the three color codes of the color bands. We ommit the tolerance band for simplicity. First, we read the image and show it. OpenCV reads images in BGR (Blue, Green, Red) format by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first image\n",
    "image = cv2.imread('./data/resistor_data/images/' + image_paths[0])\n",
    "\n",
    "# Extract the ground truth label from the file name\n",
    "label = image_paths[0].split('_')[-1][0:3]\n",
    "\n",
    "# Show image\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we convert the BGR-image to grayscale and threshold the saturated (value 255) background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to gray to threshold background\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold background\n",
    "_, threshed = cv2.threshold(image_gray, 254, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Show threshed mask\n",
    "plt.imshow(threshed, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove the sticks, we use some morphological transformations that remove all white elements that are smaller than the kernel. To do this, we define a kernel that is smaller than the core of the resistor which we want to keep, and larger than the elements we want to remove. In our case this is a rectangular kernel with size 20x20 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The kernel is chosen to be larger than the sticks, and smaller than the resistor\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 20))\n",
    "\n",
    "# We open (first closing, then dilating) the image in order to remove the sticks\n",
    "morphed_open = cv2.morphologyEx(threshed, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Show opened mask\n",
    "plt.imshow(morphed_open, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the bounding box of the resistor. Using the binary mask, we find the contour of the resistor and obtain its bounding box. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contour of resistor\n",
    "contours = cv2.findContours(morphed_open, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "\n",
    "# Print results\n",
    "print(f'There is {len(contours)} contour found in the binary image. The contour has an area of {cv2.contourArea(contours[0])} pixels')\n",
    "\n",
    "# Get minimal area rectangle\n",
    "rect = cv2.minAreaRect(contours[0])\n",
    "\n",
    "# Print results\n",
    "print(f'\\nA minimum area rectangle is found with an upper right corner on (x, y) = {rect[0]}, height and width of {rect[1]} in pixels, \\nand an orientation of {rect[2]} degrees with the horizontal')\n",
    "\n",
    "# Draw bounding box\n",
    "debug_image = cv2.drawContours(image.copy(),[np.intp(cv2.boxPoints(rect))], 0, (0,0,255), 2)\n",
    "\n",
    "# Show bounding box\n",
    "plt.imshow(cv2.cvtColor(debug_image, cv2.COLOR_BGR2RGB), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will align the resistor with the horizontal for further analysis. To do this, we use the orientation of the bounding box and transform the image using this orientation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bounding box orientation\n",
    "angle = rect[2]\n",
    "\n",
    "# Get width and height of the image\n",
    "rows, cols = image.shape[0], image.shape[1]\n",
    "\n",
    "# Get the rotation matix to rotate the bounding box to the horizontal\n",
    "M = cv2.getRotationMatrix2D((rect[0][0],rect[0][1]), angle-90, 1)\n",
    "\n",
    "# Apply the rotation matrix to rotate the image\n",
    "image_aligned = cv2.warpAffine(image, M, (cols, rows))\n",
    "\n",
    "# Also rotate the bounding box \n",
    "pts = np.intp(cv2.transform(np.array([cv2.boxPoints((rect[0], rect[1], angle))]), M))[0]    \n",
    "pts[pts < 0] = 0\n",
    "\n",
    "# Crop the rotated image using the rotated bounding box to obtain the horizontal resistor core\n",
    "image_cropped = image_aligned[pts[0][1]:pts[3][1], pts[0][0]:pts[2][0]]\n",
    "\n",
    "# Show cropped image\n",
    "plt.imshow(cv2.cvtColor(image_cropped, cv2.COLOR_BGR2RGB), cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will detect the color bands using a combination of two thresholding masks. The HSV threshold values were calibrated earlier and the threshold values for the background and the resistor core were saved in numpy arrays (.npy files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get HSV calibration params \n",
    "hsvfile1 = np.load('./data/resistor_data/demo3_hsv_resistor.npy')\n",
    "hsvfile2 = np.load('./data/resistor_data/demo3_hsv_background.npy')\n",
    "\n",
    "# Print results\n",
    "print(f'The HSV threshold values to threshold the resistor core are: {hsvfile1}, where the first three values are the lower HSV values and the last three the upper HSV values')\n",
    "print(f'The HSV threshold values to threshold the background are: {hsvfile2}, where the first three values are the lower HSV values and the last three the upper HSV values')\n",
    "\n",
    "# Convert image to HSV to simplify thresholding\n",
    "hsv = cv2.cvtColor(image_cropped, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Apply HSV thresholding on the resistor core to remove the area in between color bands\n",
    "mask1 = cv2.bitwise_not(cv2.inRange(hsv, np.array([hsvfile1[0], hsvfile1[2], hsvfile1[4]]), np.array([hsvfile1[1], hsvfile1[3], hsvfile1[5]])))\n",
    "\n",
    "# Show mask 1\n",
    "print(\"\\nResistor core removed:\")\n",
    "plt.imshow(mask1, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Apply HSV thresholding on the resistor core to remove the background\n",
    "mask2 = cv2.inRange(hsv, np.array([hsvfile2[0], hsvfile2[2], hsvfile2[4]]), np.array([hsvfile2[1], hsvfile2[3], hsvfile2[5]]))\n",
    "\n",
    "# Show mask 2\n",
    "print(\"Background removed:\")\n",
    "plt.imshow(mask2, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Combine effects\n",
    "mask = cv2.bitwise_and(mask1, mask2)\n",
    "\n",
    "# Show cropped image\n",
    "print(\"Combined effect:\")\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Morphological transformations to remove remaining white noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 10))\n",
    "morphed_open = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "mask = cv2.morphologyEx(morphed_open, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Show cropped image\n",
    "print(\"Result after morphology:\")\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the HSV thresholds and the morphological transformations, we managed to extract the color bands from the image. In the next step we will generate three cropped images of only the color bands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the three largest contours of the color bands\n",
    "contours = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "\n",
    "# Print results\n",
    "print(f'There are {len(contours)} contours found in the binary image.')\n",
    "\n",
    "# Sort contours from left to right so that it matches our encodings\n",
    "sorted_contours = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "\n",
    "# Draw the contours on the image\n",
    "image_cropped = cv2.drawContours(image_cropped.copy(), sorted_contours, -1, (0,255,0), 3)\n",
    "\n",
    "# Show cropped image\n",
    "plt.imshow(cv2.cvtColor(image_cropped, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the three contours\n",
    "color_bands = []\n",
    "for j, ctr in enumerate(sorted_contours):\n",
    "\n",
    "    # Get the bounding box rond the contour\n",
    "    x,y,w,h = cv2.boundingRect(ctr)\n",
    "\n",
    "    # Crop the image (RGB and HSV) to the bounding box (and even a bit smaller to be sure that we only capture the pure color band)\n",
    "    roi_rgb = image_cropped[y+10:y+h-10, x+5:x+w-5]\n",
    "    roi_hsv = hsv[y+10:y+h-10, x+5:x+w-5]\n",
    "\n",
    "    # Get the HSV-values of all pixels of the color band\n",
    "    roi_h = [i for i in roi_hsv[:,:,0].ravel() if i != 0]  \n",
    "    roi_s = [i for i in roi_hsv[:,:,1].ravel() if i != 0]  \n",
    "    roi_v = [i for i in roi_hsv[:,:,2].ravel() if i != 0]  \n",
    "\n",
    "    # Get means of the HSV-values for all pixels in order to obtain one mean HSV value for the whole color band\n",
    "    mean_hsv = [np.mean(roi_h), np.mean(roi_s), np.mean(roi_v)]\n",
    "\n",
    "    # Add to data\n",
    "    color_bands.append(mean_hsv)\n",
    "\n",
    "    # Print results\n",
    "    print(f'Contour {j+1} has a mean HSV-value of {mean_hsv}')\n",
    "\n",
    "    # Show cropped image\n",
    "    plt.imshow(cv2.cvtColor(roi_rgb, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a matrix with the HSV-values of the three color bands. This is the core information that we need for the image in order to be able to classify it properly. The HSV-values of the three color bands are the essential features that we need. To visualize this, we will plot is in a 3D scatterplot. The plot shows three dots in a 3D space which represents our image. Every image in our dataset can be represented using three dots. All dots of all images represents the full dataset on which we can train a classifier that learns how to classify images in resistor values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot\n",
    "colors = {'x':'gray','r':'red','z':'brown','k':'black','b':'blue','v':'magenta','g':'green'}\n",
    "c = list(map(lambda x: colors[str(x)], list(label)))\n",
    "fig = plt.figure(figsize=(12, 9))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(color_bands[:][0], color_bands[:][1], color_bands[:][2], c=c, alpha=.6, edgecolor='k', lw=0.3)\n",
    "ax.set_xlabel('H', fontsize=14)\n",
    "ax.set_ylabel('S', fontsize=14)\n",
    "ax.set_zlabel('V', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset is available that performd the image processing steps from above on all images in the dataset. We can load it and visualize it in the scatterplot. We see that we can define some clusters. These clusters represent the different colors that are present in our dataset (red, brown, black, gray, violet, and blue). It is visible that these clusters are easily separable and that no points overlap, which would make classification harder. It is perfectly possible to separate all clusters using linear planes in the 3D space. This is an indication that the chosen features (HSV-values) are very good features to classify resistors. In a last step, we convert the classes, which are strings, to integers for proper training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV in a Pandas DataFrame\n",
    "df = pd.read_csv(\"./data/resistor_data/color_data.csv\")\n",
    "\n",
    "# Define a mapping for the color encoding\n",
    "c = df['Class'].map({'x':'gray','r':'red','z':'brown','k':'black','b':'blue','v':'magenta','g':'green'})\n",
    "\n",
    "# Print results\n",
    "print(f'The loaded Pandas DataFrame looks like (only the first five entries): \\n\\n {df.head()}')\n",
    "\n",
    "# Encode categorical labels to integers\n",
    "labelencoder= LabelEncoder() \n",
    "df['Class'] = labelencoder.fit_transform(df['Class'])\n",
    "\n",
    "# Print results\n",
    "print(f'\\nThe encoded Pandas DataFrame looks like (only the first five entries): \\n\\n {df.head()}')\n",
    "print('\\nThe dataset has a column for the H-, S-, and V-values of each row (representing one color band), as well as a column for the class of that color band.')\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(12, 9))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(df.H, df.S, df.V, c=c, alpha=.6, edgecolor='k', lw=0.3)\n",
    "ax.set_xlabel('H', fontsize=14)\n",
    "ax.set_ylabel('S', fontsize=14)\n",
    "ax.set_zlabel('V', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed to the training of the SVM. To do this, we extract the inputs (HSV-values) and output (Class) from the dataset and give it to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Support VEctor Machine model\n",
    "model = svm.SVC()\n",
    "\n",
    "# Define the inputs and outputs of the model\n",
    "inputs = df[['H', 'S', 'V']].values\n",
    "output = df['Class'].values\n",
    "\n",
    "# Train the model on the dataset\n",
    "model.fit(inputs, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this last step we will loop over all images in the dataset, extract the color bands using image processing, feeding the extracted HSV-values to the trained SVM model, and comparing the predicted result with the ground truth label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of correctly predicted samples\n",
    "correct = 0\n",
    "\n",
    "# Loop over every image in the dataset\n",
    "for i in os.listdir('./data/resistor_data/images/'):\n",
    "\n",
    "\t# Read image\n",
    "\timage = cv2.imread('./data/resistor_data/images/' + path)\n",
    "\n",
    "\t# Extract the ground truth label from the file name\n",
    "\tlabel = path.split('_')[-1][0:3]\n",
    "\n",
    "\t# Extract color bands (this function implements the image processing steps that we defined earlier)\n",
    "\tbands = extract_color_bands(image)\n",
    "\n",
    "\t# Iterate over all three color bands and add the predicted class string to the final prediction\n",
    "\tprediction = ''\n",
    "\tfor j, band in enumerate(bands):\n",
    "\n",
    "\t\t# Predict the color label of the color band\n",
    "\t\tpred = model.predict([band])\n",
    "\n",
    "\t\t# Convert the ineger encoding to the class string\n",
    "\t\tprediction += labelencoder.inverse_transform(pred)[0]\n",
    "\n",
    "\t# If the predicted label is equal to the ground truth label, count it\n",
    "\tif prediction == label: correct += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can calculate the accuracy of our model which is the number of correctly predicted samples divided by the total number of samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total number of samples\n",
    "total = len(os.listdir(\"./data/resistor_data/images\"))\n",
    "\n",
    "# Print results\n",
    "print(f'There are {total} samples in the dataset')\n",
    "print(f'\\n{correct} samples are correctly classified')\n",
    "print(f'\\nThe accuracy of the system is {(correct/total)*100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
