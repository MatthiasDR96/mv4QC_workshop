{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: object detection\n",
    "\n",
    "In this assignment, we will localize chicory in an image and obtain the optimal cutting line of the chicory. We will use the YOLOv8 keypoint detector to do this. The dataset of images containing chicory contains labels with a bounding box and two points representing the cutting line. First, we will import all necessary modules that we need to get the job done. The next parts of the code are organized in: data analysis, data preprocessing, model training, and model validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "! pip install ultralytics > /dev/null\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analyis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step, we will download the data. The data folder contains a folder with images and a folder with labels in the YOLO format. This format has a .txt file for every image with one line for each annotation. Each line contains the image class, the normalized bounding box coordinates [x_center, y_center, width, height], and the normalized coordinates of the two points [x1, y1, x2, y2]. We also use a .json file with all labels in COCO format for visualization of the labels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "if not os.path.exists('data/chicory_data'):\n",
    "    !wget -q --no-check-certificate -O dataset.zip \"https://kuleuven-my.sharepoint.com/:u:/g/personal/matthias_deryck_kuleuven_be/EUD1b3ZjnixMnG9XLTAhBSABPVeLHHEuLhq6zbygg0nb_g?e=n5lOdk&download=1\"\n",
    "    !unzip -q dataset.zip -d data\n",
    "    !rm dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a COCO object from the COCO annotations file\n",
    "coco = COCO('./data/chicory_data/witloof_dataset_coco.json')\n",
    "\n",
    "# Get the annotations for the first image\n",
    "annotations = coco.loadAnns(coco.getAnnIds(imgIds=1))\n",
    "\n",
    "# Get the image info\n",
    "img_info = coco.loadImgs(1)[0]\n",
    "height, width = img_info['height'], img_info['width']\n",
    "file_name = img_info['file_name']\n",
    "\n",
    "# Load the image\n",
    "response = requests.get(file_name)\n",
    "image = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Pot annotations\n",
    "plt.imshow(image); plt.axis('off')\n",
    "coco.showAnns(annotations, draw_bbox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a proper pipeline, we will split our total dataset into a training, validation, and testset. De model gets trained on images from the training set. After each batch, the model is validated on the validation set. After training, we can evaluate the final model on the testset. The below command creates three autosplit .txt files that contain the paths to the images of the corresponding dataset for training, validation, and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in 80% training, 10% validation, and 10% test sets\n",
    "ultralytics.data.utils.autosplit(path='./data/chicory_data/images', weights=(0.8, 0.1, 0.1), annotated_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we will train our model. The model that we use is a pretrained YOLOv8n-pose model that was trained on the COCO dataset. We use the Ultralytics API for the training and validation phase. More info on: https://docs.ultralytics.com/tasks/pose/. All model parameters are logged during training, all parameters can be visualized using Tensorboard which will be activated below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tensorboard\n",
    "%tensorboard --logdir runs/pose/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a YOLOv8 nano model for pose estimation\n",
    "model = YOLO('yolov8n-pose.yaml').load('yolov8n-pose.pt')\n",
    "\n",
    "# Training params\n",
    "epochs = 20 # All data is sent 'epoch' times through the network\n",
    "image_size = 640 # All images are resized to this size before entering the network\n",
    "\n",
    "# Train the model on the data\n",
    "results = model.train(data='./data/chicory_data/witloof_dataset.yaml', epochs=epochs, imgsz=image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we load the best model and perform a validation step on the test data. Afterwards, we show some predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = YOLO('./runs/pose/train/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model\n",
    "metrics = model.val(split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the model\n",
    "results = model('./data/chicory_data/autosplit_test.txt', stream=True)  # predict on an image\n",
    "\n",
    "# Plot results\n",
    "for r in results:\n",
    "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    plt.imshow(im)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
